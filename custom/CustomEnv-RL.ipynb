{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d303a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pygame installation\n",
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame as pg\n",
    "from pygame import image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gym Imports\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, MultiDiscrete # different types of spaces\n",
    "\n",
    "# Helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Stable baselines\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Time module to make program halt for presentation purposes\n",
    "import time\n",
    "\n",
    "# for checking duplicates in our actions\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642eff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions for use\n",
    "def load_image(file):\n",
    "    \"\"\"loads an image, prepares it for play\"\"\"\n",
    "    try:\n",
    "        surface = pg.image.load(file)\n",
    "    except pg.error:\n",
    "        raise SystemExit('Could not load image \"%s\" %s' % (file, pg.get_error()))\n",
    "    return surface.convert_alpha() # convert_alpha allows for transparency from .pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47be1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.init()\n",
    "win = pg.display.set_mode((0,0))\n",
    "pg.display.set_caption(\"Custom Environment - Guess Path\")\n",
    "\n",
    "class Robot(pg.sprite.Sprite):\n",
    "    \"\"\"Visual for AI space and movement direction\"\"\"\n",
    "    images = [load_image(\"assets/sprites/robo_R.png\"), \n",
    "              load_image(\"assets/sprites/robo_L.png\"), \n",
    "              load_image(\"assets/sprites/robo_U.png\"),\n",
    "              load_image(\"assets/sprites/robo_D.png\")]\n",
    "\n",
    "    def __init__(self, pos):\n",
    "        pg.sprite.Sprite.__init__(self, self.containers)\n",
    "        self.image = self.images[0]\n",
    "        self.setPosition(pos)\n",
    "\n",
    "    def update(self, action: int):\n",
    "        if action >= 0:\n",
    "            self.image = self.images[action]\n",
    "    \n",
    "    def setPosition(self, newPos):\n",
    "        self.rect = self.image.get_rect()\n",
    "        self.rect.x = newPos[0] - (self.rect.width / 2.0)\n",
    "        self.rect.y = newPos[1] - (self.rect.height / 2.0)\n",
    "\n",
    "class Space(pg.sprite.Sprite):\n",
    "    \"\"\"Visual for space type. Normal, positive or negative\"\"\"\n",
    "    images = [load_image(\"assets/sprites/normal.png\"), \n",
    "              load_image(\"assets/sprites/plus.png\"), \n",
    "              load_image(\"assets/sprites/minus.png\"),\n",
    "              load_image(\"assets/sprites/start.png\"), \n",
    "              load_image(\"assets/sprites/goal.png\")]\n",
    "    spaceType = 0\n",
    "\n",
    "    def __init__(self, pos, jumpDistance):\n",
    "        pg.sprite.Sprite.__init__(self, self.containers)\n",
    "        \n",
    "        self.jumpDistance = jumpDistance\n",
    "        \n",
    "        if(jumpDistance == 0):  # neutral movement - does not push Robot\n",
    "            self.image = self.images[0]\n",
    "            self.spaceType = 0\n",
    "        elif(jumpDistance > 0): # positive movement - pushes robot forward\n",
    "            self.image = self.images[1]\n",
    "            self.spaceType = 1\n",
    "        else:                    # negative movement - pushes robot backward\n",
    "            self.image = self.images[2]\n",
    "            self.spaceType = 2\n",
    "\n",
    "        self.rect = self.image.get_rect()\n",
    "        self.rect.x = pos[0] - (self.rect.width / 2.0)\n",
    "        self.rect.y = pos[1] - (self.rect.height / 2.0)\n",
    "        \n",
    "    def setType(self, spaceType):\n",
    "            self.image = self.images[spaceType]\n",
    "            self.spaceType = spaceType\n",
    "            self.jumpDistance = 0\n",
    "            \n",
    "            if spaceType == 3:\n",
    "                self.spaceType = 0 # if the current space type is the start, set it to a nothing type\n",
    "            \n",
    "            if spaceType == 1:\n",
    "                self.jumpDistance = 2\n",
    "            elif spaceType == 2:\n",
    "                self.jumpDistance = -2\n",
    "\n",
    "    def getType(self):\n",
    "        return self.spaceType\n",
    "\n",
    "# Initialize Game Groups\n",
    "all = pg.sprite.RenderUpdates()\n",
    "    \n",
    "Space.containers = all\n",
    "Robot.containers = all\n",
    "\n",
    "# Board does not require rendering\n",
    "        \n",
    "class Board():\n",
    "    \"\"\"Board that sets up and displays all spaces\"\"\"\n",
    "    def __init__(self, maxCols, pos):\n",
    "        self.spaces = [[], [], [], [], []]\n",
    "        \n",
    "        self.maxCols = maxCols\n",
    "        \n",
    "        if self.maxCols < 1:\n",
    "            self.maxCols = 1 # cap minimum value to max rows in case of emergency\n",
    "\n",
    "        # Thanks to Jack Malone for help with this loop\n",
    "        for index, value in enumerate(self.spaces):\n",
    "            for y in range(self.maxCols):\n",
    "                value.append(Space(((64 * y) + pos[0], (64 * index) + pos[1]), 0))\n",
    "                            \n",
    "        self.middle = (len(self.spaces) // 2)\n",
    "        self.playerPos = [self.middle,0]\n",
    "        self.goal = [self.middle, self.maxCols - 1]\n",
    "                        \n",
    "    def setStartEnd(self):\n",
    "        self.spaces[self.playerPos[0]][self.playerPos[1]].setType(3)\n",
    "        self.spaces[self.goal[0]][self.goal[1]].setType(4)\n",
    "                        \n",
    "    def update(self, robot: Robot, action: int):\n",
    "        additionalReward = 0 # calculate reward for robot here\n",
    "        \n",
    "        if action >= 0:\n",
    "            if action == 0: # right\n",
    "                  if self.playerPos[1] < self.maxCols - 1:\n",
    "                        self.playerPos[1] += 1\n",
    "            elif action == 1: # left\n",
    "                 if self.playerPos[1] > 0:\n",
    "                        self.playerPos[1] -= 1\n",
    "            elif action == 2: # up\n",
    "                if self.playerPos[0] > 0:\n",
    "                        self.playerPos[0] -= 1\n",
    "            elif action == 3: # down\n",
    "                if self.playerPos[0] < len(self.spaces) - 1:\n",
    "                        self.playerPos[0] += 1\n",
    "\n",
    "            # first check to see if the position has to be updated\n",
    "            # as the robot may move onto a push space\n",
    "            pushValue = self.spaces[self.playerPos[0]][self.playerPos[1]].jumpDistance\n",
    "            \n",
    "            if pushValue > 0:\n",
    "                additionalReward = 2\n",
    "            elif pushValue < 0:\n",
    "                additionalReward = -2\n",
    "            \n",
    "            if pushValue != 0: # only do push calculations if the robot has to be pushed\n",
    "                self.playerPos[1] += pushValue\n",
    "\n",
    "                # now check to see if the player has jumped outside the bounds of the board\n",
    "                # only generate reward for a successful jump\n",
    "                if self.playerPos[1] > self.maxCols - 1:\n",
    "                    self.playerPos[1] = self.maxCols - 1\n",
    "                    additionalReward = 0\n",
    "                elif self.playerPos[1] < 0:\n",
    "                    self.playerPos[1] = 0\n",
    "                    additionalReward = 0\n",
    "                \n",
    "            # now that the robot has moved, update it's position\n",
    "            robot.setPosition(((self.playerPos[0] * 64) + 96, (self.playerPos[1] * 64) + 96))\n",
    "            \n",
    "            return additionalReward\n",
    "            \n",
    "    def initializeSpaces(self):\n",
    "        # When we want to disable non-deterministic elements,\n",
    "        # we run this to pre-set all spaces\n",
    "        # first, reset all spaces back to 0\n",
    "        for x in range(5):\n",
    "            for y in range(self.maxCols):\n",
    "                self.spaces[x][y].setType(0)\n",
    "        \n",
    "        # now pre-set all the requires blue and red spaces\n",
    "        self.spaces[4][3].setType(1)\n",
    "        self.spaces[0][4].setType(2)\n",
    "        self.spaces[1][4].setType(2)\n",
    "        self.spaces[2][4].setType(2)\n",
    "        self.spaces[3][4].setType(2)\n",
    "        self.spaces[4][4].setType(2)\n",
    "        \n",
    "        self.spaces[4][7].setType(1)\n",
    "        self.spaces[0][8].setType(2)\n",
    "        self.spaces[1][8].setType(2)\n",
    "        self.spaces[2][8].setType(2)\n",
    "        self.spaces[3][8].setType(2)\n",
    "        self.spaces[4][8].setType(2)\n",
    "        \n",
    "        self.spaces[2][11].setType(1)\n",
    "        self.spaces[0][12].setType(2)\n",
    "        self.spaces[1][12].setType(2)\n",
    "        self.spaces[2][12].setType(2)\n",
    "        self.spaces[3][12].setType(2)\n",
    "        self.spaces[4][12].setType(2)\n",
    "        \n",
    "    def randomizeSpaces(self):\n",
    "        # The AI can easily determine where to go if all the blue spaces stay still\n",
    "        # What if the blue spaces moved during each run of the environment?\n",
    "        # That's what we do here, we pick a new spot for each of the Blue spaces if random is enabled.\n",
    "        firstSpot = random.randint(0,4)\n",
    "        secondSpot = random.randint(0,4)\n",
    "        thirdSpot = random.randint(0,4)\n",
    "        \n",
    "        # Now that we have the new 3 spots, we need to clear the row of any previous spots.\n",
    "        # range(5) gives 0 -> 4, so we can use it in place of the x pos\n",
    "        for x in range(5):\n",
    "            self.spaces[x][3].setType(0)\n",
    "            self.spaces[x][7].setType(0)\n",
    "            self.spaces[x][11].setType(0)\n",
    "            \n",
    "        # now that the spaces are cleared, place the new blue spots\n",
    "        self.spaces[firstSpot][3].setType(1)\n",
    "        self.spaces[secondSpot][7].setType(1)\n",
    "        self.spaces[thirdSpot][11].setType(1)\n",
    "        \n",
    "    def winCheck(self):\n",
    "        if(self.playerPos[0] == self.goal[0] \n",
    "           and self.playerPos[1] == self.goal[1]):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "pg.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbb078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathEnv(Env):\n",
    "    win = pg.display.set_mode((1600,800))\n",
    "    pg.display.set_caption(\"Custom Environment - Guess Path RL\")\n",
    "    bg = load_image('assets/sprites/background.png')\n",
    "    board = Board(16, (100,100))\n",
    "    shouldRandomize = False\n",
    "    environmentPaused = False\n",
    "    \n",
    "    def __init__(self, randomizeBoard, waitTime):\n",
    "        # Actions: 0 - Right, 1 - Left, 2 - Up, 3 - Down\n",
    "        self.action_space = Discrete(4)\n",
    "        self.timeToWait = waitTime\n",
    "        \n",
    "        self.shouldRandomize = randomizeBoard\n",
    "        \n",
    "        # Create observation space\n",
    "        # Position on board, and what space type is directly up, right, down and left of the AI\n",
    "        # a space type of 0 is considered to be off board\n",
    "        # space type 1 is neutral, 2 is positive and 3 is negative\n",
    "        # space type 4 is the goal space\n",
    "        self.observation_space = MultiDiscrete([80, 5, 5, 5, 5])\n",
    "        \n",
    "        # Determine starting state upon initialization\n",
    "        self.state = self.determineState()\n",
    "        # \n",
    "        self.alloted_length = 60\n",
    "\n",
    "        self.board.initializeSpaces()\n",
    "            \n",
    "        if(randomizeBoard):\n",
    "            self.board.randomizeSpaces()\n",
    "           \n",
    "        self.board.setStartEnd()\n",
    "            \n",
    "        self.robo = Robot(((self.board.playerPos[0] * 64) + 96, \n",
    "                  (self.board.playerPos[1] * 64) + 96))\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Update Environment elements\n",
    "        self.robo.update(action)\n",
    "        \n",
    "        additionalReward = self.board.update(self.robo, action)\n",
    "        \n",
    "        # With elements updated, determine state, reward etc\n",
    "        self.state = self.determineState()\n",
    "        \n",
    "        # Reduce alloted length to use environment by time moved via pygame clock\n",
    "        self.alloted_length -= 1\n",
    "\n",
    "        # TODO: Calculate reward\n",
    "        reward = -1 + additionalReward\n",
    "        \n",
    "        # Check if environment is done\n",
    "        if self.alloted_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "        if self.board.winCheck():\n",
    "            reward += 70 # when finding the goal, end the environment and give a good reward\n",
    "            done = True\n",
    "        \n",
    "        # Needed during the return\n",
    "        info = {}\n",
    "  \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        win.blit(self.bg, (0,0))\n",
    "        for r in self.board.spaces:\n",
    "                for c in r: # position all spaces to the correct top left position\n",
    "                    win.blit(c.image, (c.rect.x, c.rect.y))\n",
    "\n",
    "        win.blit(self.robo.image, (self.robo.rect.y, self.robo.rect.x))\n",
    "        pg.display.update()\n",
    "        time.sleep(self.timeToWait)\n",
    "        \n",
    "    def pauseEnv(self, paused):\n",
    "        self.environmentPaused = paused\n",
    "    \n",
    "    def reset(self):\n",
    "        if not self.environmentPaused:\n",
    "            # Reset game elements\n",
    "            self.board.initializeSpaces()\n",
    "\n",
    "            if(self.shouldRandomize):\n",
    "                self.board.randomizeSpaces()\n",
    "\n",
    "        self.board.playerPos = [self.board.middle,0] # reset player pos on board\n",
    "        self.robo.setPosition(((self.board.playerPos[0] * 64) + 96, \n",
    "              (self.board.playerPos[1] * 64) + 96)) # place robo onto the correct spot\n",
    "\n",
    "        self.board.setStartEnd()\n",
    "        \n",
    "        # Reset starting state\n",
    "        self.state = self.determineState()\n",
    "        # Reset alloted time to interact\n",
    "        self.alloted_length = 60\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def calculateReward(self):\n",
    "        # calculate reward based for AI\n",
    "        pass\n",
    "    \n",
    "    def determineState(self):\n",
    "        # the current state is where the player currently is on the board\n",
    "        pos = self.board.playerPos\n",
    "        currentSpace = 0\n",
    "        up = 0\n",
    "        left = 0\n",
    "        down = 0\n",
    "        right = 0\n",
    "        \n",
    "        # pos[0] moves along the x axis, 0, 1, 2 etc...\n",
    "        # pos[1] moves along the y axis, 0, maxCols * 1, maxCols * 2...\n",
    "        # adding the two together gives us the space they are on\n",
    "        # 0,0 gives 0\n",
    "        # 1,0 gives 1\n",
    "        # 0,1 gives maxCols\n",
    "        currentSpace = pos[1] + (pos[0] * self.board.maxCols)\n",
    "        \n",
    "        # now that we know where the AI is, we will see what each space type is in all directions    \n",
    "        if pos[0] > 0:\n",
    "            up = self.board.spaces[pos[0] - 1][pos[1]].getType()\n",
    "        if pos[1] > 0:\n",
    "            left = self.board.spaces[pos[0]][pos[1] - 1].getType()\n",
    "        if pos[0] < len(self.board.spaces) - 1:\n",
    "            down = self.board.spaces[pos[0] + 1][pos[1]].getType()\n",
    "        if pos[1] < self.board.maxCols - 1:\n",
    "            right = self.board.spaces[pos[0]][pos[1] + 1].getType()\n",
    "\n",
    "        \n",
    "        state = [currentSpace, up, left, down, right]\n",
    "        \n",
    "        \n",
    "        return state\n",
    "    \n",
    "pg.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ea358",
   "metadata": {},
   "source": [
    "# Test Environment\n",
    "\n",
    "Change the Cells below to Code (Click the Cell then Cell -> Cell Type -> Code OR CTRL + Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e941649",
   "metadata": {},
   "source": [
    "env = PathEnv(False, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa4362",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#-# Run this cell to test that the Environment works properly\n",
    "#-# This will randomly pick from a Discrete action step, no model is used here.\n",
    "\n",
    "pg.init()\n",
    "win = pg.display.set_mode((1160,460))\n",
    "pg.display.set_caption(\"Custom Environment - Guess Path RL\")\n",
    "\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    #env.board.randomizeSpaces()\n",
    "    \n",
    "    while not done:\n",
    "        pg.event.get()\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward         \n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n",
    "pg.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07e4b1",
   "metadata": {},
   "source": [
    "pg.quit() # optional pygame quit in case of error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb240d3b",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('training', 'logs')\n",
    "training_log_path = os.path.join(log_path, 'GuessPath_PPO_Random_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766e414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = PathEnv(False, 0.0)\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf197fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PathEnv(True, 0.25) # change to code cell if you wish to train an existing model further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d562672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=240000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560c303",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "guesspath_path = os.path.join('training', 'saved_models', 'GuessPath_PPO_Random_320000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(guesspath_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model) # uncomment to delete the model after saving it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4001c",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change path end on guesspath_path to change loaded model\n",
    "guesspath_path = os.path.join('training', 'saved_models', 'GuessPath_PPO_Random_320000')\n",
    "env = PathEnv(True, 0.25) # set environment if not set already\n",
    "model = PPO.load(guesspath_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d51da4",
   "metadata": {},
   "source": [
    "# Watch Model\n",
    "### With a loaded model, it will be used with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c031e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.display.init()\n",
    "win = pg.display.set_mode((1124,460))\n",
    "pg.display.set_caption(\"Custom Environment - Guess Path RL\")\n",
    "\n",
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        pg.event.get()\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs) # predict returns two, but we only require action            \n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n",
    "pg.display.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.display.quit() # run in case of error / crash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449080f1",
   "metadata": {},
   "source": [
    "### Dynamically Reinforce Learning\n",
    "- If our Model continuously picks the same types of actions, they may be in a state they are not expecting.\n",
    "- To fix this, we can attempt to re-train the Model for a much smaller time.\n",
    "- This isn't the greatest fix, as any board state that is very different each time will cause constant re-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actionCounter = 4 # number of actions to be counted before attempting a repeat check\n",
    "repeatThreshold = 2 # number of times an action has to be repeated before the model is considered to be stuck\n",
    "\n",
    "def checkRepeats(actions):\n",
    "    duplicates = {key:value for key, value in dict(Counter(actions)).items() if value > 1}\n",
    "    \n",
    "    print(duplicates)\n",
    "\n",
    "    if len(duplicates) != 2:\n",
    "        return False # only check for actions that don't pick any actions outside of the same 2 actions\n",
    "    \n",
    "    # we want to make sure the 2 repeated actions are opposite actions\n",
    "    # so the model is either choosing left/right, or up/down continously\n",
    "    dupKeys = list(duplicates.keys())\n",
    "    exit = True\n",
    "    \n",
    "    # 0 / 1 - Left / Right\n",
    "    if (dupKeys[0] == 0 and dupKeys[1] == 1) or (dupKeys[0] == 1 and dupKeys[1] == 0):\n",
    "        exit = False\n",
    "    # 2 / 3 - Up / Down\n",
    "    if (dupKeys[0] == 2 and dupKeys[1] == 3) or (dupKeys[0] == 3 and dupKeys[1] == 2):\n",
    "        exit = False\n",
    "    \n",
    "    if exit:\n",
    "        return False\n",
    "    \n",
    "    # we will now have multiple key value pairs\n",
    "    # the key is the action, and the value is the number of times that action is picked\n",
    "    # using this, we can loop through all the key value pairs, and determine if any are being chosen too many times.\n",
    "    for repeats in duplicates.values():\n",
    "        print(repeats)\n",
    "        if repeats >= repeatThreshold:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def retrain(env, model):\n",
    "    env.pauseEnv(True) # stop the board from being randomized or changed from it's current state\n",
    "    model.learn(total_timesteps=10000) # re-train on a much smaller scale\n",
    "    env.reset() # reset the environment now that re-training is complete\n",
    "    env.pauseEnv(False) # allow the board to change now that re-training is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6116c",
   "metadata": {},
   "source": [
    "# Dynamically Run Model\n",
    "- With the above functions declared, we can now let the model play in our environment.\n",
    "- If the loop detects the Model is picking duplicate actions and is stuck, it will re-train the model briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92727e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PathEnv(True, 0.25) # set environment if not set already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.display.init()\n",
    "win = pg.display.set_mode((1124,460))\n",
    "pg.display.set_caption(\"Custom Environment - Guess Path RL\")\n",
    "actions = []\n",
    "\n",
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    actions.clear()\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        pg.event.get()\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs) # predict returns two, but we only require action\n",
    "        actions.append(action)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "        if len(actions) >= actionCounter: # check the last few actions for repeated actions           \n",
    "            if checkRepeats(actions):\n",
    "                retrain(env, model) \n",
    "                actions.clear()\n",
    "            actions.clear()\n",
    " \n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n",
    "pg.display.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.display.quit()\n",
    "env.pauseEnv(False) # reset in case of crash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9db64",
   "metadata": {},
   "source": [
    "### Viewing Logs with Tensorboard\n",
    "#### Note: This should not be run within Jupyter, as it will freeze the notebook while it runs.\n",
    "#### However, it can be run within the Notebook purely for demonstration purposes, so it will be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # uncomment this if you wish to only view logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = 'PPO_2_NoRandom320000'\n",
    "\n",
    "log_path = os.path.join('training', 'logs')\n",
    "training_log_path = os.path.join(log_path, check)\n",
    "\n",
    "print(training_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path}\n",
    "# if you are running this from jupyter, go to http://localhost:6006 to access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e24b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
